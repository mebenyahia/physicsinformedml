{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks (PINNs) Interactive Demo\n",
    "\n",
    "This notebook provides an interactive demonstration of Physics-Informed Neural Networks for solving partial differential equations.\n",
    "\n",
    "## What are PINNs?\n",
    "\n",
    "Physics-Informed Neural Networks (PINNs) are a class of neural networks that incorporate physical laws (expressed as PDEs) directly into the learning process. Unlike traditional neural networks that learn purely from data, PINNs can:\n",
    "\n",
    "1. **Learn from limited data** by leveraging known physics\n",
    "2. **Solve forward and inverse problems** in PDEs\n",
    "3. **Handle noisy and sparse data** effectively\n",
    "4. **Provide mesh-free solutions** to complex PDEs\n",
    "\n",
    "## The Heat Equation\n",
    "\n",
    "We'll solve the 1D heat equation:\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$$\n",
    "\n",
    "where:\n",
    "- $u(x,t)$ is the temperature at position $x$ and time $t$\n",
    "- $\\alpha$ is the thermal diffusivity\n",
    "\n",
    "**Boundary Conditions:**\n",
    "- $u(0, t) = 0$ (left boundary fixed at 0)\n",
    "- $u(1, t) = 0$ (right boundary fixed at 0)\n",
    "\n",
    "**Initial Condition:**\n",
    "- $u(x, 0) = \\sin(\\pi x)$ (initial temperature distribution)\n",
    "\n",
    "**Exact Solution:**\n",
    "$$u(x, t) = \\sin(\\pi x) e^{-\\pi^2 \\alpha t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pinn_heat_equation import HeatEquationPINN, plot_solution\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize the PINN\n",
    "\n",
    "Let's create our Physics-Informed Neural Network. The network takes $(x, t)$ as input and outputs $u(x, t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize the PINN solver\n",
    "alpha = 0.1  # Thermal diffusivity\n",
    "layers = [2, 50, 50, 50, 1]  # Network architecture: 2 inputs (x,t), 1 output (u)\n",
    "\n",
    "solver = HeatEquationPINN(alpha=alpha, layers=layers)\n",
    "\n",
    "print(\"PINN Initialized!\")\n",
    "print(f\"Thermal diffusivity (α): {alpha}\")\n",
    "print(f\"Network architecture: {layers}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in solver.model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualize the Initial Condition\n",
    "\n",
    "Let's see what the initial temperature distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "u_initial = np.sin(np.pi * x)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x, u_initial, linewidth=2, label='Initial Condition: sin(πx)')\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('u(x, 0)', fontsize=12)\n",
    "plt.title('Initial Temperature Distribution', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"This sine wave will diffuse over time according to the heat equation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the PINN\n",
    "\n",
    "Now we train the neural network to satisfy:\n",
    "1. The PDE in the domain\n",
    "2. The boundary conditions\n",
    "3. The initial condition\n",
    "\n",
    "The loss function combines all three components:\n",
    "$$L = L_{PDE} + L_{BC} + L_{IC}$$\n",
    "\n",
    "**Note:** Training might take a few minutes. Adjust `n_epochs` for faster/slower training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_epochs = 5000      # Number of training iterations\n",
    "n_pde = 10000        # Number of collocation points for PDE\n",
    "n_bc = 200           # Number of boundary condition points\n",
    "n_ic = 200           # Number of initial condition points\n",
    "learning_rate = 1e-3 # Learning rate\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "loss_history = solver.train(\n",
    "    n_epochs=n_epochs,\n",
    "    n_pde=n_pde,\n",
    "    n_bc=n_bc,\n",
    "    n_ic=n_ic,\n",
    "    lr=learning_rate,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Training Progress\n",
    "\n",
    "Let's examine how the loss decreased during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: All losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(loss_history['total'], label='Total Loss', linewidth=2)\n",
    "plt.semilogy(loss_history['pde'], label='PDE Loss', alpha=0.7)\n",
    "plt.semilogy(loss_history['bc'], label='BC Loss', alpha=0.7)\n",
    "plt.semilogy(loss_history['ic'], label='IC Loss', alpha=0.7)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (log scale)', fontsize=12)\n",
    "plt.title('Training Loss Components', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Final losses (last 20%)\n",
    "plt.subplot(1, 2, 2)\n",
    "start_idx = int(0.8 * len(loss_history['total']))\n",
    "plt.plot(range(start_idx, len(loss_history['total'])), \n",
    "         loss_history['total'][start_idx:], linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Total Loss', fontsize=12)\n",
    "plt.title('Final Training Phase', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final total loss: {loss_history['total'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare PINN Solution with Exact Solution\n",
    "\n",
    "Now let's compare our PINN's predictions with the known exact solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive visualization\n",
    "fig = plot_solution(solver)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe plots show:\")\n",
    "print(\"  - Top left: PINN predicted solution u(x,t)\")\n",
    "print(\"  - Top right: Exact analytical solution\")\n",
    "print(\"  - Bottom left: Absolute error between PINN and exact solution\")\n",
    "print(\"  - Bottom right: Training loss history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Calculate Error Metrics\n",
    "\n",
    "Let's quantify how accurate our PINN solution is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test points\n",
    "x_test = np.linspace(0, 1, 100)[:, None]\n",
    "t_test = np.linspace(0, 1, 100)[:, None]\n",
    "X_test, T_test = np.meshgrid(x_test.flatten(), t_test.flatten())\n",
    "X_flat = X_test.flatten()[:, None]\n",
    "T_flat = T_test.flatten()[:, None]\n",
    "\n",
    "# Predictions\n",
    "U_pred = solver.predict(X_flat, T_flat)\n",
    "U_exact = solver.exact_solution(X_flat, T_flat)\n",
    "\n",
    "# Calculate metrics\n",
    "l2_error = np.linalg.norm(U_pred - U_exact) / np.linalg.norm(U_exact)\n",
    "max_error = np.max(np.abs(U_pred - U_exact))\n",
    "mean_error = np.mean(np.abs(U_pred - U_exact))\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Error Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Relative L2 Error:       {l2_error:.8f}\")\n",
    "print(f\"Maximum Absolute Error:  {max_error:.8f}\")\n",
    "print(f\"Mean Absolute Error:     {mean_error:.8f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Solution at Different Time Steps\n",
    "\n",
    "Let's see how the temperature distribution evolves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time snapshots\n",
    "time_steps = [0.0, 0.2, 0.5, 1.0]\n",
    "x = np.linspace(0, 1, 200)[:, None]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "for i, t_val in enumerate(time_steps):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    \n",
    "    # Predict\n",
    "    t = np.ones_like(x) * t_val\n",
    "    u_pred = solver.predict(x, t)\n",
    "    u_exact = solver.exact_solution(x, t)\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(x, u_pred, 'b-', linewidth=2, label='PINN')\n",
    "    plt.plot(x, u_exact, 'r--', linewidth=2, label='Exact', alpha=0.7)\n",
    "    plt.xlabel('x', fontsize=11)\n",
    "    plt.ylabel('u(x, t)', fontsize=11)\n",
    "    plt.title(f't = {t_val:.1f}', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim([-0.1, 1.1])\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how the sine wave decays exponentially over time,\")\n",
    "print(\"with the PINN solution closely matching the exact solution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test on Specific Points\n",
    "\n",
    "Let's verify the solution at some specific $(x, t)$ points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test points\n",
    "test_points = [\n",
    "    (0.5, 0.0),\n",
    "    (0.5, 0.25),\n",
    "    (0.5, 0.5),\n",
    "    (0.25, 0.5),\n",
    "    (0.75, 0.5)\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'x':>6} {'t':>6} {'PINN u(x,t)':>14} {'Exact u(x,t)':>14} {'Error':>12}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for x_val, t_val in test_points:\n",
    "    x_pt = np.array([[x_val]])\n",
    "    t_pt = np.array([[t_val]])\n",
    "    \n",
    "    u_pred = solver.predict(x_pt, t_pt)[0, 0]\n",
    "    u_exact = solver.exact_solution(x_pt, t_pt)[0, 0]\n",
    "    error = abs(u_pred - u_exact)\n",
    "    \n",
    "    print(f\"{x_val:6.2f} {t_val:6.2f} {u_pred:14.8f} {u_exact:14.8f} {error:12.8f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Physics Integration**: PINNs incorporate the PDE directly into the loss function, ensuring the solution respects physical laws.\n",
    "\n",
    "2. **Mesh-Free**: Unlike traditional numerical methods (finite differences, finite elements), PINNs don't require a mesh.\n",
    "\n",
    "3. **Automatic Differentiation**: PyTorch's autograd enables efficient computation of derivatives needed for the PDE.\n",
    "\n",
    "4. **Flexibility**: PINNs can handle complex geometries and nonlinear PDEs.\n",
    "\n",
    "5. **Data Efficiency**: By encoding physics, PINNs can learn from limited data.\n",
    "\n",
    "## Extensions to Try\n",
    "\n",
    "- Change the thermal diffusivity `alpha`\n",
    "- Modify the network architecture\n",
    "- Try different initial conditions\n",
    "- Add noise to boundary/initial conditions\n",
    "- Solve 2D heat equation\n",
    "- Implement other PDEs (wave equation, Burgers' equation, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Raissi, M., Perdikaris, P., & Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. *Journal of Computational Physics*, 378, 686-707.\n",
    "\n",
    "2. Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., & Yang, L. (2021). Physics-informed machine learning. *Nature Reviews Physics*, 3(6), 422-440.\n",
    "\n",
    "3. Cuomo, S., Di Cola, V. S., Giampaolo, F., Rozza, G., Raissi, M., & Piccialli, F. (2022). Scientific machine learning through physics–informed neural networks: Where we are and what's next. *Journal of Scientific Computing*, 92(3), 88."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
